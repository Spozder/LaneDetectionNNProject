{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def cnn_model(features, labels, mode, config):\n",
    "    #data format: (index_in_batch, height, width, channel)\n",
    "    # mode: Indicate it is in training or testing or predicting\n",
    "\n",
    "    shape = np.append([-1], features.shape[1:])\n",
    "    height, width = features.shape[1], features.shape[2]\n",
    "    convKernel = [3, 3]\n",
    "    stridesSize = (1, 1)\n",
    "    poolSize = [2, 2]\n",
    "    dropout = 0.2\n",
    "\n",
    "    # Input reshape\n",
    "    input_layer = tf.cast(tf.reshape(features, shape), tf.float32)\n",
    "\n",
    "    #Convolutional layer 1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs = input_layer, filters = 8, kernel_size = convKernel, \n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"conv1\")\n",
    "    \n",
    "    #Convolutional layer 2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs = conv1, filters = 16, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"conv2\")\n",
    "\n",
    "    #Pooling\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "            inputs = conv2, pool_size = poolSize, strides = 2, name = \"pooling1\")\n",
    "\n",
    "    #Convolutional layer 3\n",
    "    conv3 = tf.layers.conv2d(\n",
    "            inputs = pool1, filters = 16, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"conv3\")\n",
    "\n",
    "    dropout1 = tf.layers.dropout(inputs = conv3, rate = dropout, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    #Convolutional layer 4\n",
    "    conv4 = tf.layers.conv2d(\n",
    "            inputs = dropout1, filters = 32, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"conv4\")\n",
    "\n",
    "    dropout2 = tf.layers.dropout(inputs = conv4, rate = dropout, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    #Convolutional layer 5\n",
    "    conv5 = tf.layers.conv2d(\n",
    "            inputs = dropout2, filters = 32, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"conv5\")\n",
    "\n",
    "    dropout3 = tf.layers.dropout(inputs = conv5, rate = dropout, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "            inputs = dropout3, pool_size = poolSize, strides = 2, name = \"pooling2\")\n",
    "\n",
    "    #Convolutional layer 6\n",
    "    conv6 = tf.layers.conv2d(\n",
    "            inputs = pool2, filters = 64, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"conv6\")\n",
    "\n",
    "    dropout3 = tf.layers.dropout(inputs = conv6, rate = dropout, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    #Convolutional layer 7\n",
    "    conv7 = tf.layers.conv2d(\n",
    "            inputs = dropout3, filters = 64, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"conv7\")\n",
    "\n",
    "    dropout4 = tf.layers.dropout(inputs = conv7, rate = dropout, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    pool3 = tf.layers.max_pooling2d(\n",
    "            inputs = dropout4, pool_size = poolSize, strides = 2, name = \"pooling3\")\n",
    "\n",
    "    [_, height, width, channel] = pool3.get_shape().as_list()\n",
    "\n",
    "    unsample1 = tf.image.resize_nearest_neighbor(\n",
    "            images = pool3, size = ( height * 2, width * 2), name = \"unsampling1\")\n",
    "    \n",
    "    #Deconvolution layer 1\n",
    "    deconv1 = tf.layers.conv2d_transpose(\n",
    "            inputs = unsample1, filters = 64, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"deconv1\")\n",
    "\n",
    "    dropout5 = tf.layers.dropout(inputs = deconv1, rate = dropout, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    #Deconvolution layer 2\n",
    "    deconv2 = tf.layers.conv2d_transpose(\n",
    "            inputs = dropout5, filters = 64, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"deconv2\")\n",
    "\n",
    "    dropout5 = tf.layers.dropout(inputs = deconv2, rate = dropout, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    [_, height, width, channel] = dropout5.get_shape().as_list()\n",
    "    \n",
    "    unsample2 = tf.image.resize_nearest_neighbor(\n",
    "            images = dropout5, size = (height * 2, width * 2), name = \"unsampling2\")\n",
    "\n",
    "    #Deconvolution layer 3\n",
    "    deconv3 = tf.layers.conv2d_transpose(\n",
    "            inputs = unsample2, filters = 32, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"deconv3\")\n",
    "\n",
    "    dropout6 = tf.layers.dropout(inputs = deconv3, rate = dropout, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    #Deconvolution layer 4\n",
    "    deconv4 = tf.layers.conv2d_transpose(\n",
    "            inputs = dropout6, filters = 32, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"deconv4\")\n",
    "\n",
    "    dropout7 = tf.layers.dropout(inputs = deconv4, rate = dropout, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    #Deconvolution layer 5\n",
    "    deconv5 = tf.layers.conv2d_transpose(\n",
    "            inputs = dropout7, filters = 16, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"deconv5\")\n",
    "\n",
    "    dropout8 = tf.layers.dropout(inputs = deconv5, rate = dropout, training = (mode == tf.estimator.ModeKeys.TRAIN))\n",
    "\n",
    "    [_, height, width, channel] = dropout8.get_shape().as_list()\n",
    "\n",
    "    unsample3 = tf.image.resize_nearest_neighbor(\n",
    "            images = dropout8, size = (height *2, width * 2), name = \"unsampling3\")\n",
    "\n",
    "    #Deconvolution layer 6\n",
    "    deconv6 = tf.layers.conv2d_transpose(\n",
    "            inputs = unsample3, filters = 16, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"deconv6\")\n",
    "\n",
    "    #Deconvolution layer 7\n",
    "    deconv7 = tf.layers.conv2d_transpose(\n",
    "            inputs = deconv6, filters = 1, kernel_size = convKernel,\n",
    "            strides = stridesSize, activation = tf.nn.relu, name = \"deconv7\")\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.mean_squared_error(predictions = deconv7, labels = labels)\n",
    "    \n",
    "    predictions = {\n",
    "        \"predict_lane\": deconv7\n",
    "    }\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "      # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = { \"accuracy\": tf.metrics.mean(tf.losses.mean_squared_error(labels=labels, predictions=predictions[\"predict_lane\"]))}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './tmp/lane_prediction', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f81e3dc55c0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/lane_prediction/model.ckpt-20\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 21 into ./tmp/lane_prediction/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.1510872, step = 21\n",
      "INFO:tensorflow:Saving checkpoints for 33 into ./tmp/lane_prediction/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 40 into ./tmp/lane_prediction/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.15299653.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-04-24-03:58:34\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/lane_prediction/model.ckpt-40\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-04-24-04:03:59\n",
      "INFO:tensorflow:Saving dict for global step 40: accuracy = 0.15338957, global_step = 40, loss = 0.15338957\n",
      "{'accuracy': 0.15338957, 'loss': 0.15338957, 'global_step': 40}\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sapphire/anaconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(unused_args):\n",
    "    #load data\n",
    "    labels = pickle.load(open(\"full_CNN_labels.p\", \"rb\" ))\n",
    "    labels = np.array(labels)\n",
    "    labels = labels / 255\n",
    "    train_images = pickle.load(open(\"full_CNN_train.p\", \"rb\" ))\n",
    "    train_images=np.array(train_images)\n",
    "    \n",
    "    # train data / test data = 0.8\n",
    "    rate = 0.8\n",
    "\n",
    "    # split the data\n",
    "    train_data, test_data, train_label, test_label = \\\n",
    "    train_test_split(train_images, labels, train_size = rate, test_size = 1 - rate)\n",
    "\n",
    "    # Add a logger\n",
    "#     tensor_logger = {\"acc\": \"metrics_acc\"}\n",
    "#     hook = tf.train.LoggingTensorHook(tensors = tensor_logger, every_n_iter= 100)\n",
    "\n",
    "    #Train\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=train_data,\n",
    "    y=train_label,\n",
    "    batch_size=200,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "    \n",
    "    classifier = tf.estimator.Estimator(\n",
    "        model_fn= cnn_model,\n",
    "        model_dir= \"./tmp/lane_prediction\")\n",
    "\n",
    "    classifier.train( input_fn=train_input_fn, steps=20)\n",
    "    \n",
    "    #Test\n",
    "    test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = test_data,\n",
    "    y = test_label,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False)\n",
    "    test_result = classifier.evaluate(input_fn= test_input_fn)\n",
    "    print(test_result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
